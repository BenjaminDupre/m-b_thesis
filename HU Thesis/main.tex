\documentclass[12pt,oneside,openright]{report}

\usepackage[utf8]{inputenc}
\usepackage[scaled]{helvet}

\renewcommand\familydefault{\sfdefault} 
\usepackage[T1]{fontenc}
\usepackage{fancyhdr,xcolor}

\usepackage{graphicx} % Add the graphicx package for including images
\usepackage{geometry}
\usepackage{amsmath} % Add this line to your LaTeX preamble to use \text
\usepackage{afterpage}
\usepackage{caption}
\usepackage{float}
\usepackage{xcolor}
\usepackage[style=authoryear,backend=biber]{biblatex}
\addbibresource{bibliog.bib}
\usepackage[colorlinks=true,linkcolor=black,anchorcolor=black,citecolor=black,filecolor=black,menucolor=black,runcolor=black,urlcolor=black]{hyperref}\usepackage{graphicx}
\geometry{
  a4paper,
  left=20mm,
  right=20mm,
  top=4.5cm,
  headheight=4cm,
  bottom=3.5cm,
  footskip=3cm
}

\renewcommand*{\bibfont}{\footnotesize}

\newcommand{\changefont}{
    \fontsize{18}{16}\selectfont
}
\definecolor{boxcl}{HTML}{1188BB}
\definecolor{tubred}{HTML}{1188BB}



\begin{document}

\begin{titlepage}
    \centering
    % Include the image with a width of one-third of the page
    \includegraphics[width=0.5\textwidth]{Hu-logo.png}
    \vspace{2cm}
    
    {\huge \textbf{Multisensory Integration in Virtual Reality: Effect of Passive Haptic Stimulation}\par}
    \vspace{2cm}
    {\LARGE Master Thesis\par}
    \vspace{0.5cm}
    {\textbf{submitted in fulfillment of the requirements for the degree}\par}
    Master of Science (M.Sc.)\par
    {\textbf{in the master's program ``Mind and Brain''}\par}
    \vspace{1.5cm}
    {\textbf{Humboldt-Universität zu Berlin}\par}
    {\textbf{Berlin School of Mind and Brain}\par}
    \vfill
    \raggedright
    \begin{tabular}{ll}
        \textbf{Handed in by}: & Benjamin Dupré \\
        \textbf{Date of birth:} & 26.04.1986\\
       \textbf{ Address:} & Hoppestraße 16, 13409, Berlin \\
    \end{tabular}
    \vfill
    \begin{tabular}{ll}
        \textbf{1. Supervisor:}& Dr. Michael Gaebler \\
        \textbf{2. Supervisor:}& Professor Dr. Arno Villringer  \\
    \end{tabular}
    \vfill
    {Berlin, den \today \par}
\end{titlepage}

\section*{1. Introduction}
\subsection*{1.2 Problem \& Significance}

In interoceptive research, a pivotal finding reveals the impact of visceral signals on our processing of external stimuli. Specific brain mechanisms responsible for predicting signals within the body, notably changes related to heart systole, play a crucial role in diminishing our perception of external signals like touch, vision, and auditory cues \cite{esra_p, AL2021118247, Grund643, motyka, Park2014}. While this muting effect has been well-documented in psychophysical experimental setups and individual sense modalities, the influence of cardiac phases on cognitive processes like attention and memory has been under scrutiny from the early stages of research.

For instance, studies examining cognitive processes such as attention and memory have explored how the cardiac cycle impacts word retention. Words detected during systole were less effectively remembered compared to those detected during diastole \cite{Garfinkel2013-st}. Recent variations in experimental setups and stimuli have moved beyond phase-locked and passive stimuli, investigating active sampling of the world. Evidence suggests that more eye movement occurs during systolic phases while more fixation happens during diastolic phases \cite{GalvezPol2018ActiveSI}.

Furthermore, expanding into sensory integration, recent research has delved into how the cardiac phase influences multisensory integration \cite{SALTAFOSSI2023108642}. Findings indicate that during diastole, there's a higher level of integration for Audio-Tactile and Visuo-Tactile stimuli compared to Audio-Visual stimuli when using the Race Model Inequality approach.

As the relevance of cardiac-cycle phases in sensory integration becomes more evident, research aims to develop explanations that encompass multiple observations. One such explanation involves understanding interoceptive processes through a predictive coding framework. A recent study employing a Markov decision process (MDP) using current cardiac cycle and visual stimuli suggests that this computational framework could explain observed phenomena \cite{Allen2022}, though further testing is required.

As research progresses into theoretical generalizations or practical applications, there's a growing need for ecological validity. To simultaneously test cognitive processes and multisensory integration, experiments need to align more closely with real-world scenarios. Improving ecological validity is crucial in understanding how body-brain phenomena translate into human psychology \cite{schmuckler2001ecological}.

Immersive Virtual Reality (IVR) emerges as a tool facilitating a seamless transition from psychophysics findings to psychological phenomena. IVR, known for its effectiveness in studying cognitive processes within controlled yet complex scenarios, traditionally relies on visual displays and head-hand movement tracking. However, the integration of VR head-mounted displays with ECG and haptic devices presents new challenges, both practical and technical, as well as in terms of alignment with existing literature \cite{Klotzsche2023}.

This research aims to leverage Virtual Reality to bridge the gap between psychophysics findings and everyday experiences. It seeks to validate an experimental VR setup that extends two lines of research: multisensory modulation and the influence of cardiac cycles on environmental sampling. By doing so, it aims to bring these findings closer to everyday life and enhance ecological validity. However, assessing the true impact of this phenomenon on everyday experiences, such as post-exercise sensations, poses a challenge. It necessitates a delicate balance between obtaining clear psychophysical results and integrating them with other cognitive functions.


\subsection*{1.3 Thesis Topic \& Goal}

The primary objective of this study is to investigate the feasibility of incorporating touch-cardiac-cycle modulation studies into Interactive Virtual Reality (IVR) setups. IVR, being a system that often involves visual, tactile, and proprioceptive senses, inherently engages multiple senses or is intentionally designed as a multisensory experience. To facilitate a comparative analysis of results, a relevant recent study by Martina Saltafossi on vision, touch, and hearing as multisensory pairs \cite{SALTAFOSSI2023108642} serves as a suitable reference. While there is limited research on two multisensory modalities and none to my knowledge using IVR, this study aims to bridge that gap. However, before delving into specific goals, it is necessary to define the concept of touch, as it encompasses various modes.

The extended classification of tactile sensation \cite{Healy2003HandbookOP} provides a useful framework for understanding touch, categorizing it into five different modes based on the presence or absence of voluntary movement: (1) tactile (cutaneous) perception, (2) passive kinesthetic perception, (3) passive haptic perception, (4) active kinesthetic perception, and (5) active haptic perception. For this thesis, touch is defined as passive haptic perception generated by a vibrating Data-Glove. Based on this definition, three main goals are derived:

\begin{itemize}
  \item[(i)] Assess the impact of passive haptic stimuli on reported immersion. This investigation quantifies the influence of passive haptic stimuli on questionnaire scores, shedding light on touch's role in creating a sense of presence. Saltafossi's study refers to this as "body illusions induced by multisensory conflicts between exteroceptive sensory modalities, such as vision and touch."
    
  \item[(ii)] Confirm findings supporting the redundancy signal effect (RSE) and some aspects of the race model inequality (RMI). Checking for example the order of the cumulative distibution functions (CDF) for different RT. Additionally comparing single modal condition visual ($F_V$) and bimodal conditions were touch matches ($F_{V=T}$) or doesn’t match ($F_{V \neq T}$) the visual space. 
\end{itemize}

By examining how passive haptic stimuli influence the response time in the motor-memory task, this study seeks to replicate the overall findings of the reference paper \parencite*{SALTAFOSSI2023108642} and validate behaviorally the effects of passive haptic stimuli in a IVR motor-memory task. In a wider frame, this research aims to enhance our understanding of IVR as a research tool and further validate findings on multisensory integration and perception.

\section*{2. Methods}
    \subsection*{2.1 Participants}
    From an original pool of 23 participants that presneted to do the task we finish we 20 participats. Two of them did not fill all questionnaires and a third one was above the age limit  so we had to exclude them from the analysis, leaving us with 20 participants. The call for participants was answered considerably more by women (15) than men (5). The age across the sample was consistently around 25 years old, with the exception of one participant ($\mu=25.1 , \sigma=6.3$).
    \begin{figure}[h]
        \centering
        \includegraphics[width=12cm]{/home/perdices/Dokumente/Github/m-b_thesis/Analysis/figures/participants.png}
        \caption{Participants Composition}
        \label{fig:mesh1}
    \end{figure}
    
    \subsection*{2.2 Materials}
    \subsubsection*{2.2.1 Electrocardiogram (ECG):}
Heart rate data is collected using an Arduino Uno and a SparkFun Single Lead Heart Rate Monitor - AD8232. The collected data is transferred through a USB 2.0 connection and integrated into the Unity log file at a frequency of 133 Hz. Based on live ECG device \parencite{TimsECG}.

\subsubsection*{2.2.2 Head Mounted Display \& Lighthouses:}
The VR setup includes an HTC Vive head-mounted display (HMD) with two lighthouses. The headset specifications include a Dual AMOLED 3.6" diagonal display, with 1080 x 1200 pixels per eye (2160 x 1200 pixels combined), a 90 Hz refresh rate, and a 110-degree field of view. The lighthouses are equipped with SteamVR Tracking, G-sensors, gyroscopes, and proximity sensors. Both the HMD and lighthouses are connected using USB 2.0. For this study, the VR controllers were not used, and instead, hand tracking was performed using the Leap Motion sensor.

\subsubsection*{2.2.3 Leap Motion Controller:}
The Leap Motion Controller has a field of view of 150x120 degrees, with a variable range of roughly 80 cm (arm's length). It weighs 32 grams and is mounted on the HMD. The device features two 640x240 infrared cameras with a frame rate of 120 fps.

\subsubsection*{2.2.4 Data Gloves:}
The data gloves used in the study are equipped with magnetic sensors and connected to Unity using a microUSB connection. These gloves provide haptic feedback through 10 vibrotactile actuators, offering a wide range of tactile sensations with 1,024 levels of intensity. The gloves also incorporate complete finger tracking using six 9-axis Inertial Measurement Units (IMUs). These IMUs enable precise tracking of finger movements, allowing for accurate gesture recognition and enhanced interaction in virtual environments.
    \subsection*{2.3 Task}
    After being debriefed and receiving information about the experiment, participants completed the following tasks:
\begin{enumerate}
\item[(i)] Edinburgh Handedness Questionnaire
\item[(ii)] PRE-Cybersickness Questionnaire
\end{enumerate}

Following the completion of the first set of questionnaires, the participants were taken to another room where the IVR (Immersive Virtual Reality) equipment was set up. This equipment included a head-mounted display (HMD), data gloves, and an ECG (Electrocardiogram) device. Participants underwent a short training session before proceeding with the heartbeat count task and the IVR memory-motor task.

\begin{enumerate}
\item[(iii)] PRE-Heart Beat Count Task (HCT) for one minute. (This task is not considered in this thesis.)
\item[(iv)] IVR Memory-Motor Task: In this environment, participants were positioned in front of a virtual table and given sufficient time to acclimate to the virtual surroundings. A sketch of a puzzle was displayed in front of the virtual room, which they needed to memorize. During the memorization phase, participants kept their virtual hands open with palms facing up. Subsequently, the sketch disappeared from their visual field, and a red ball was introduced from the top, appearing in either one of the hands. Participants observed a template on the table, which was an identical representation of the initial sketch they had memorized. Their task was to place the ball in the correct location on the template as quickly as possible. Throughout 108 trials, three different conditions (relevant haptic stimuli, irrelevant haptic stimuli, and no haptic stimuli) were randomly presented an equal number of times (36 times each). The trials appeared rapidly, one after the other. The start of each trial was marked by placing the ball in a hand, and the end of the trial was marked by the moment the ball reached the designated location on the template.
\item[(v)] POST-Heart Beat Count Task (HCT) for one minute. (This task is not considered in this thesis.)
\end{enumerate}

The final step of the experiment involved two questionnaires aimed at extracting information on several relevant fields for the goal of this thesis:
After the IVR part the participants filled a again the cybersicknesss quiestionaire as well as for the first time an overall Subjective Evaluation Questionaire.
\begin{enumerate}
    \item[(vi)] Virtual Reality Subjective Evaluation Questionnaire
    \item[(vii)] POST-Cybersickness Questionnaire
\end{enumerate}
    \subsection*{2.4 Mesurements}
    \subsubsection*{Immersive Virtual Reality (VR):}

The VR experience was presented and tracked using an HTC Vive head-mounted display (HMD), two lighthouses, a Leap Motion sensor, and Haptic Data Gloves. Movement data from the data gloves, Leap Motion device, and the HMD was collected. For movement analysis, only the wrist movements tracked by the Leap Motion device were considered, excluding the fingertips' magnetic tracking sensor data. All movements were recorded in a Euclidean coordinate system (X, Y, Z) with the original calibrating point set at (0, 0, 0). This provided a total of nine streaming sources of data (e.g., Headset X, Headset Y, Headset Z, and so on). Notably, rotational data was not included in the analysis.

Additionally, in the game output data, there are flags that signal if a button was pressed, if the ball is placed in the holder, and when the trial started.

\subsubsection*{Electrocardiogram (ECG):}

Heart rate data was collected using a USB cable and integrated into Unity Engine. This information was coupled with all other Unity data at a frequency of 133 Hz.

\subsubsection*{Questionnaires:}

\begin{enumerate}
\item[(i)] Virtual Reality Subjective Evaluation Questionnaire: This self-made questionnaire consists of 26 items oriented towards capturing whether the VR experience felt real for the participant or not. It explores the level of engagement, hand movement, task difficulty, and other controlling factors. The questionnaire uses a Likert scale ranging from one to seven.
\item[(ii)] PRE/POST-Cybersickness Questionnaire: The version applied in this study is a shorter adaptation of the simulator sickness questionnaire (SSQ) \parencite*{avpsy}. It employs a Likert scale ranging from one to four, with labels going from "not present," "somewhat," "clearly," and "very strongly." The questionnaire includes 16 items based on symptoms, such as "fatigue" and "general discomfort," among others.
\end{enumerate}

\subsection*{2.5 Data Analysis}
    
All repsonse times were constructed considering the time elapsed between the moment the ball is entering the scene in the trial and the moment it explodes or disapears. All trials in which the error button was pressed were removed. Before the analyis, I performed an outlier correction applying an exclusion of data points that deviated by more than 3 × 1.4826 × median absolute deviations (MADs) from the median, corresponding to 3 SDs if data are normally distributed \parencite{Innes2019ACA}. There were no answers removed on account of being to fast. Answers to slow were 13\% of trials removed. In the final sample there are 1826 RT (aprox. 24 per condition and participant). 
    
    To be able to compare with our reference Saltafossi' paper we need to confirm the well-known redundant signal effect (i.e. faster RT to bimodal stimulation than single one) and built part of the Race model Inequality to test that it holds for ever period of $t$.
    
    To do this I followed the procedures in \cite{Ulrich2007,Innes2019ACA}. Because there is only one individual stimuli and two Bimodal Stimuli I run a simplified version with no "bounding sum". The calculation goes in the following 3 steps. First step is to build the empirical cumulative density functions (CDF) for all three conditions (Bimodal pairs: ($F_{V=T}$); ($F_{V \neq T}$) and Single Signal: $F_V$ ). The second step is to determine the percentiles and the third step is to aggregate across participants computing separate paired t tests at each
    of the percentiles under examination. For more detailed calculations refere to \Cite{Ulrich2007}.

    \section*{3. Results}
    \subsection*{(i) Assessing the Impact of the Haptic Globe on Reported Immersion}
    
    Nineteen respondents answered 27 questions, rating them on a scale from 1 (Does Not Apply) to 7 (Totally Applies). The key findings from the questionnaire are as follows:
    
    \begin{enumerate}
        \item In question number 24, the perceived increase in immersion due to the haptic globes was high ($\text{Mdn} = 6$, $\mu = 6$, $\sigma = 0.76$). Furthermore, the task was considered enjoyable at least some of the time ($\text{Mdn} = 6$, $\mu = 5.4$, $\sigma = 1.04$).
        
        \item Question 26 revealed that haptic feedback was perceived as either not significantly improving performance or having a neutral effect ($\text{Mdn} = 3$, $\mu = 3.6$, $\sigma = 1.49$). Similarly, in question 12, the perception of haptic feedback improving response time was generally rated as neutral to not applicalbe ($\text{Mdn} = 3$, $\mu = 3.7$, $\sigma = 1.74$). In question 7, when asked about the impact on results, haptic feedback was perceived as not applicable ($\text{Mdn} = 6$, $\mu = 6$, $\sigma = 0.76$).
    
        \item Notably, the assertion that it was very challenging to remember the position of the red ball ($\text{Mdn} = 2$, $\mu = 2.9$, $\sigma = 1.45$) was generally disagreed upon. Conversely, in question 8, which asked about the ease of remembering the location of the red ball, responses were as expected ($\text{Mdn} = 5$, $\mu = 5.1$, $\sigma = 1.37$).
    
        \item The highest variance was observed in question 13 ($\text{Mdn} = 5$, $\mu = 4.2$, $\sigma = 1.79$), indicating that haptic feedback made it easier to place the ball. Similarly, question 18, which inquired about the ease of counting heartbeats at the beginning of the experiment, also showed significant variance ($\text{Mdn} = 4$, $\mu = 4$, $\sigma = 1.79$). 
        
    \end{enumerate}
    
    For more details please go to the supplement section 

    
    \subsection*{(ii) Touch stimuli influence the response time}
\section*{4. Discussion}


%-------- CREATING BIBLIOGRAPHY

%\bibliographystyle{plain} % Choose your style
%\bibliography{bibliog.bib}  % Use your actual .bib file name
\pagebreak
\section*{Supplement}
    \begin{figure}[H]
        \centering
        \includegraphics[angle=90, width=\textwidth, height=20cm, keepaspectratio]{/home/perdices/Dokumente/Github/m-b_thesis/Analysis/figures/questionaire_fig.png}
        \caption{Results: Virtual Reality Subjective Evaluation Questionnaire}
        \label{fig:mesh2}
    \end{figure}
  

\pagebreak
\paragraph{\textbf{References}}
\printbibliography[heading=none]

\end{document}

