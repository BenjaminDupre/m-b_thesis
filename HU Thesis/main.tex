\documentclass[12pt,oneside,openright]{report}

\usepackage[utf8]{inputenc}
\usepackage[scaled]{helvet}
\usepackage{subcaption} % Add the subcaption package for subfigures
\usepackage{dirtytalk} %quoting package
\renewcommand\familydefault{\sfdefault} 
\usepackage[T1]{fontenc}
\usepackage{fancyhdr,xcolor}

\usepackage{graphicx} % Add the graphicx package for including images
\usepackage{geometry}
\usepackage{amsmath} % Add this line to your LaTeX preamble to use \text

\usepackage{pdfpages}
\usepackage{afterpage}
\usepackage{caption}
\usepackage{float}
\usepackage{xcolor}
\usepackage[style=authoryear,backend=biber]{biblatex}
\addbibresource{bibliog.bib}
\usepackage[colorlinks=true,linkcolor=black,anchorcolor=black,citecolor=black,filecolor=black,menucolor=black,runcolor=black,urlcolor=black]{hyperref}\usepackage{graphicx}
\geometry{
  a4paper,
  left=20mm,
  right=20mm,
  top=3cm,
  headheight=4cm,
  bottom=3.5cm,
  footskip=3cm
}

\renewcommand*{\bibfont}{\footnotesize}

\newcommand{\changefont}{
    \fontsize{18}{16}\selectfont
}
\definecolor{boxcl}{HTML}{1188BB}
\definecolor{tubred}{HTML}{1188BB}



\begin{document}

\begin{titlepage}
    \centering
    % Include the image with a width of one-third of the page
    \includegraphics[width=0.5\textwidth]{Hu-logo.png}
    \vspace{2cm}
    
    {\huge \textbf{Multisensory Integration in Virtual Reality: Effects of Passive Haptic Stimulation}\par}
    \vspace{2cm}
    {\LARGE Master Thesis\par}
    \vspace{0.5cm}
    {\textbf{submitted in fulfillment of the requirements for the degree}\par}
    Master of Science (M.Sc.)\par
    {\textbf{in the master's program ``Mind and Brain''}\par}
    \vspace{1.5cm}
    {\textbf{Humboldt-Universität zu Berlin}\par}
    {\textbf{Berlin School of Mind and Brain}\par}
    \vfill
    \raggedright
    \begin{tabular}{ll}
        \textbf{Handed in by}: & Benjamin Dupré \\
        \textbf{Date of birth:} & 26.04.1986\\
       \textbf{ Address:} & Hoppestraße 16, 13409, Berlin \\
    \end{tabular}
    \vfill
    \begin{tabular}{ll}
        \textbf{1. Supervisor:}& Dr. Michael Gaebler \\
        \textbf{2. Supervisor:}& Professor Dr. Arno Villringer  \\
    \end{tabular}
    \vfill
    {Berlin, \today \par}
\end{titlepage}

\section*{1. Introduction}
%\subsection*{1.1 Problem \& Significance}

We have all heard at some point that our body behaves like an orchestra, with the brain as the conductor. Within this orchestra, multiple specialized musicians are organized together creating a melody grander than any individual musician could aspire to achieve alone. However, it's plausible that there is more than one orchestra coordinator, but rather a team of orchestra coordinators \parencite{Morten2021}. Recent findings suggest an unseen conductor outside the brain, providing subtle cues that dictate whether the symphony focuses on its harmonies or the audience's mood. This concealed orchestra director serves as an analogy for the role the heart cycle\footnote{Refers to the sequence of events that occur during each heart beat. Involving the contraction (systole) and relaxation (diastole) of the heart chambers} plays in signal perception and multisensory integration\footnote{Multisensory integration refers to the ability to synthesize information arriving from cross-modal stimuli}.

The heart cycle has become central to ongoing research in interoception\footnote{Interoception refers to the process by which the nervous system senses, interprets, and integrates signals originating from within the body, providing a moment-by-moment mapping of the body's internal landscape across conscious and unconscious levels.\parencite{Khalsa2017InteroceptionAM}}. The electrical discharge generated by the heart every pulsation, is transmited to the brian \footnote{The baroreceptor-mediated signals are transmitted through the glosso-pharyngeal and vagus nerves to the brainstem nuclei, reaching the nucleus tractus solitarii (NTS) and the parabrachial nucleus (PBN), where they are involved in the homeostatic control of blood pressure and heart rate.\parencite{SALTAFOSSI2023108642}} and there plays a significant role on how we process external stimuli (e.g. touch) \parencite{esra_p}. This influence is extensively observed in both psychophysics\footnote{The study of the relationship between the physical world and its sensory representations. Perceptual experiments often recruit only a few subjects; these subjects are highly trained, and each contribute a large number of observations. \parencite{KINGDOM2012234,WASKOM2019100}} and cognitive experimental setups\footnote{Cognitive experiments typically recruit larger samples, train for task comprehension rather than for expertise, and focus analyses on population-level parameters \parencite{WASKOM2019100}}. These findings constitute our initial set of facts, now we need an understanding of the operations performed by these findings \parencite{Barlow2012PossiblePU}. 

In this thesis, I propose a virtual reality (VR) experimental setup as a mechanism to generate this understanding. However, what are these findings preceisly? In the following section, I will mention some of these findings categorized into two groups: the psychophysical effects and the cognitive effects of the cardiac cycle. On a third section of the introduction, we look into the imporance of linking these findings in a ecological valid way \footnote{To sample stimuli or conditions in a way that respects the distribution and covariance of ecological variables if we hope to achieve generalizability beyond the boundaries of the experimental manipulation.\parencite{NASTASE2020117254}} and incorporating psychophysical findings and technics.

\subsubsection*{Psychophysical Heart Cycle Effects}

Psychophysical research looks into the relationship between physical phenomena and the perceptual effects they generate. These experiments are usually carried out with a single perceptual modality and high precision measurements. In heart cycle literature, stimuli is presented in sync with a specific cardiac phase (phase-lock). Findings show that the heart cycle plays a crucial role in diminishing or increasing our perception of external signals in touch, vision, and auditory cues \parencite{SALTAFOSSI2023108642}. In the somatosensory realm, the accuracy of detecting near-threshold stimuli showed a higher level during the diastolic phase of the cardiac cycle in contrast to systole \parencite{esra_p, AL2021118247, Grund643, motyka}. For vision and auditory stimuli, diastole improves accuracy and reaction time compared to systole \parencite{SALTAFOSSI2023108642}. However, real-life stimuli are rarely presented in a single modality. How does the heart cycle behave in multisensory situations?

A recent study investigates the integration of multiple simultaneous sensorial modalities \parencite{SALTAFOSSI2023108642}. Explored the cardiac phase modulation of multisensory integration. Forty participants in good health performed a Simple Detection Task involving unimodal (Auditory, Visual, Tactile) and bimodal (Audio-Tactile, Audio-Visual, Visuo-Tactile) stimuli. These stimuli were presented either 250 ms after the R-peak of the electrocardiogram (systole) or 500 ms after (diastole). The study found a generalized impact of cardiac cycle phases on detecting both single and combined stimuli. Reaction times prove speedier for stimuli presented during diastole when contrasted with those in systole.

Additionally, this study utilizes the well-known Race Model Inequality (RMI) and response times (RT) to measure multisensory integration. In sensory modality testing, redundant signal effects refers to how individuals respond faster to redundant sensory signals compared to unisensory signals. One proposed explanation to the RSE model is Race Model Inequality (RMI). This model suggests that evidence for each signal is accumulated separately by parallel decision units (e.g. one for audition and one for vision) and that the first unit to reach its threshold triggers a response\parencite{Innes2019ACA,MILLER1982247}. 

Once again, the diastolic cardiac phase enhances the response to the sensory signal. The integration of Audio-Tactile and Visuo-Tactile stimuli showed higher integration when presented during diastole as opposed to systole, unlike Audio-Visual stimuli. This observation suggests a potential specificity in the influence of the cardiac phase on multisensory integration, particularly in stimuli involving somatosensory (e.g. tactile) inputs.

So far, all studies involve the passive presentation of stimuli and phase-locked conditions. It would seem that the role of the heart cycle as an orchestrator works under very specific circumstances, limited to the passive presentation of stimuli and locked to a particula heart cycle. In our day-to-day lives, stimuli comes to us in a constant stream, through multiple modalities; as well as, we actively seek specific stimuli. Would a more naturalistic stimuli interaction still show this cardiac phase influence?

\subsubsection*{Cognitive Heart Cycle Effects}

The second group of studies delves into higher cognitive functions. For instance, an illustrative study aims to measure if there's a difference in how we memorize a word presented during a specific cardiac phase. Words were shown within a limited attentional timeframe, synchronized with various cardiac cycle phases. This sought to investigate whether natural baroreceptor stimulation affects word detection and subsequent memory. The study reveals that recalling words presented during systole is lower compared to those presented at diastole. This memory decrease during systole is more pronounced for words identified with low confidence and heightened among individuals with lower interoceptive sensitivity, measured through a heartbeat counting task \parencite{Garfinkel2013-cy}.

Another two studies look to understadn if the way in which we actively sample the world is similarly modulated by the phase of the cardiac cycle. The first study focus lies on exploring the role of the heartbeat in active information sampling, investigating whether humans unconsciously arrange their environment to encounter pertinent signals during preferred cardiac phases. In the visual memory experiment's encoding phase, participants navigated through a series of emotional pictures, aiming to memorize them for a subsequent recognition test. Through self-paced key presses, they initiated the display of brief (100 ms) images. The study's findings unveil fluctuations in self-triggered picture onsets throughout the cardiac cycle, notably heightened during cardiac systole, yet without impacting memory performance. This leads the study to conclude that active information gathering incorporates signals related to the heartbeat.\parencite{Kunzendorf2019-vz}. A similar study confirm these findings. It was achieved by presenting participants with arrays to compare in size. They measured participants' eye movements, heart rate, and response times. The authors similarly found a significant coupling of saccades, subsequent fixations, and blinks with the cardiac cycle. They observed that more eye movement occurs during systolic phases while more fixation happens during diastolic phases, thus demonstrating an active perceptual role.\parencite{GalvezPol2018ActiveSI}.

So far, we've observed the influence of the heart cycle on perception, recognition, and active sampling. How do these pieces of information connect to the heart cycle's overarching function? Do they suggest an organizing role for the heart cycle? To draw an analogy, is the heart cycle akin to being part of the brain's team of orchestra conductors? If it is, what mechanism enables it to simultaneously influence such a wide array of functions?

\subsubsection*{Linking facts together}

As our understanding of the role of the cardiac cycle grows, the gaps between perception of external stimuli and cognitive functions widens. How does the heart cycle manage to influence diverse cognitive functions, such as word recognition and stimuli perception?

Several of the previously mentioned papers offer some explanation. Most point towards an interoceptive predictive framework . This framework posits that repetitive bodily signals, like the heartbeat cycle, can be predicted and suppressed to prevent entry into conscious perception, inadvertently leading to the suppression of external stimuli\parencite{AL2021118247, SALTAFOSSI2023108642,Allen2022}. 

Another paper formulates a complete computational interoceptive predictive framework \parencite{Allen2022}. This paper goes beyond by utilizing Markov Desicion Process. The Agents infer which policy they are persuing (relax or aroused) to produce the best mapping possible. The policies are defined operationally in terms of transitioning beween interoceptive states. For example, in relaxed state the shifts in probability among cardiac states result in two phases of diastole and one of systole. In contrast, arousal prompts an immediate transition from the initial diastolic state to systole. Essentially, arousal triggers cardiac acceleration and extends the average duration spent in systole. Its premise assumes that precise visual information is available only during specific phases of the cardiac cycle, contingent upon one's state of arousal. Among its findings, the paper demonstrates the model's ability to replicate various psychological and physiological phenomena found in the interoceptive inference literature. It provides a means to test such a model.

The models porvided so far are used to explain for stimuli presented during a specific heart cycle, in which we are influeced by our proprioceptive state. Although they would only account for exteroceptive suppression and offer no explanation as to how they link with behavioral or cognitive outcomes. At the moment this theories are in need of behavioral work since this provides understanding, whereas physiological interventions test causality\parencite{KRAKAUER2017480}.

To accomplish this, a more comprehensive experimental framework should encompass not just psychophysical stimuli but also broader cognitive functions extending beyond mere perception. Such tasks can help refine and assess an individual's strategies and level of involvement, minimizing the influence of uncontrolled higher-order processes \parencite{WASKOM2019100}. The initial phase of this approach involves replicating previous studies and aligning the experimental conditions more closely with real-world situations. This enhances the ecological validity and furthers our comprehension of how body-brain interactions manifest in human psychology \parencite{schmuckler2001ecological}. This process involves building on previous findings while integrating new experimental setups.

\subsubsection*{The Thesis}

We are proposing new experimental setup using Immersive Virtual Reality (IVR). IVR, known for its effectiveness in studying cognitive processes within controlled yet complex scenarios, traditionally relies on visual displays and head-hand movement tracking. We propose a setup using VR head-mounted displays with Electrocardiogram (ECG) and haptic devices. However, the integration of these devices presents new challenges, both practical and technical, as well as in terms of alignment with existing literature \parencite{Klotzsche2023}.

Particularly in the realm of psychophysical experimental setups, notable distinctions emerge. For instance, most studies in existing literature involve very brief periods of Reaction Time (RT). Due to the nature of IVR, RT tends to be considerably longer. Furthermore, IVR inherently involves multiple senses,  often involving visual, tactile, and proprioceptive senses and making all studies inherently multisensory. In contrast with most psychophysical studies that are multisensory. 

Therefore, the primary objective of this thesis is to validate the manipulation in the context of a multisensory heart cycle study. This is why the chosen study to mimic results is \textcite{SALTAFOSSI2023108642}, which is to my knowledge the only study looking into heart cycle and multisensory integration. Specifically to test the feasibility of manipulating touch within a heart cycle-IVR setups. To achieve this, one outcome is to assess the impact of passive haptic stimuli on reported immersion. Here the participats reported that the gloves increased the sense of inmertion, altough as not to have a relevant effect in the performance of the task. Additionally, the respone times (RT) showed a significant overall difference for the touch condition, thus validating the set up.

A secondary objective of this study is to to mimic the findings from \textcite{SALTAFOSSI2023108642}. Relevant for this study is the redundancy signal effect (RSE) and race model inequality (RMI). We observed that the overall performance partially adhered to the RSE, notably showing the congruent bimodal condition (V = T) significantly faster than the uni-modal condition (V). No significant differences were found between incongruent bimodal condition ($V \neq T$) and the single condition (V). Additinoally, when looking into the cumulative distibution functions (CDF) for different RT, we replicated the findings showing again faster bimodal conditions than unimodal conditions. Nonetheless, with potential violations specifically for the first 200ms

Considerable distinctions exist between the stimuli employed in this study and the referenced one. In this investigation, sole reliance resides upon vision as single modality, whereas the reference study has measurments for single modalities vision, touch and audio. Tactile in the reference study is determined for each participant with the method of the limits. In our study is simulated by a vibrotactile glove. Furthermore, this inquiry revolves around conditions primarily focused on the tactile sense\footnote{Touch, within this thesis, adopts an encompassing classification of tactile sensation, encapsulating five distinct modes predicated upon the presence or absence of voluntary movement: (1) tactile (cutaneous) perception, (2) passive kinesthetic perception, (3) passive haptic perception, (4) active kinesthetic perception, and (5) active haptic perception \parencite{Healy2003HandbookOP}}. For the scope of this thesis, touch specifically denotes passive haptic perception generated through a vibrational Data-Glove, compare to the reference study were is applied through a electrical current. Vibro-tactile stimu.lation significantly affected RT in participants and shows promising results for future heart-cycle analysis.

By probing the influence of passive haptic stimuli on response time within a motor-memory task, this study replicates the principal observations delineated in heart cycle multisensory integration literature \parencite{SALTAFOSSI2023108642}, thereby confirming in IVR as means of developing pschophysical investigation of cognition.

%I am Here at this point % I should jump to results and Discussion Section.

\section*{2. Methods}
\subsection*{Participants}
The call for participants targeted healthy, non-smoking German-speaking individuals between 18 and 30 years old. Initially, 23 individuals participated in the study, but ultimately, only 20 participants were included in the final sample. Among the three excluded individuals, two failed to complete all necessary questionnaires, while the third exceeded the age limit. Notably, a greater number of women (15) responded to the call compared to men (5). The average age across the sample hovered around 25 years, with a slight deviation observed in one participant ($\mu=25.1, \sigma=6.3$).

\begin{figure}[h]
    \centering
    \includegraphics[width=15cm]{/home/perdices/Dokumente/Github/m-b_thesis/Analysis/figures/participants.png}
    \captionsetup{justification=justified, margin={2cm,2cm}, font={small}}
    \caption{Participants Composition}
    \label{fig:mesh1}
\end{figure}

    
\subsection*{Materials}
\subsubsection*{Electrocardiogram (ECG):}
Heart rate data was collected using an Arduino Uno and a SparkFun Single Lead Heart Rate Monitor - AD8232. The collected data is transferred through a USB 2.0 connection and integrated into the Unity log file at a frequency of 133 Hz. Compared to a clinical ECG, this device entails a serial interface that can send triggers via USB directly to a computer and software (e.g. Unity, Matlab) with minimal delay due to its architecture. Its software and hardware is open-source and publicly available \parencite{TimsECG}.

\subsubsection*{Head Mounted Display \& Lighthouses:}
The VR setup includes a HTC Vive head-mounted display (HMD) with two lighthouses. The headset specifications include a Dual AMOLED 3.6" diagonal display, with 1080 x 1200 pixels per eye (2160 x 1200 pixels combined), a 90 Hz refresh rate, and a 110-degree field of view. The lighthouses are equipped with SteamVR Tracking, G-sensors, gyroscopes, and proximity sensors. Both the HMD and lighthouses are connected using USB 2.0. For this study, the VR controllers were not used, and instead, hand tracking was performed using the Leap Motion sensor.

\subsubsection*{Leap Motion Controller:}
The Leap Motion Controller has a field of view of 150x120 degrees, with a variable range of roughly 80 cm (arm's length). It weighs 32 grams and is mounted on the HMD. The device features two 640x240 infrared cameras with a frame rate of 120 fps.

\subsubsection*{Data Gloves:}
The data gloves used in the study are equipped with magnetic sensors and connected to Unity using a microUSB connection. These gloves provide haptic feedback through 10 vibrotactile actuators, offering a wide range of tactile sensations with 1,024 levels of intensity. The gloves also incorporate complete finger tracking using six 9-axis Inertial Measurement Units (IMUs). These IMUs enable precise tracking of finger movements, allowing for accurate gesture recognition and enhanced interaction in virtual environments.


\subsection*{Task}

Participants, following debriefing on Covid-specific rules, information privacy, and ethical norms, were briefed on the experiment. Subsequently, they consented and completed all subsequent tasks. It's crucial to note that I didn't utilize all tasks from the original study\footnote{Original study VR/ECG-study Akbal/Villinger} as this thesis pursues a different hypothesis. Nevertheless, considering that all participants completed all questionnaires and tasks, the following description encompasses all tasks for transparency.

\textbf{Questionnaires:} Prior to the IVR experience, participants completed the Edinburgh Handedness Questionnaire to determine their handedness. The PRE-Cybersickness Questionnaire and POST-Cybersickness Questionnaire were administered before and after the IVR task to assess sickness symptoms in participants. Following the IVR experience, participants filled out the Virtual Reality Subjective Evaluation Questionnaire, designed to gather their perceptions of immersion, particularly considering tactile stimuli. 

\textbf{Heartbeat Count Task (HCT):} Participants performed a one-minute heartbeat count task before and after the IVR task. Note that this task is not considered within this thesis due to being outside the scope of this secondary study.

After completing the initial questionnaires and HCT, participants moved to another room where the IVR equipment was set up. This included a head-mounted display, data gloves, and an ECG device. Participants received a brief training session before proceeding with the heartbeat count task and the IVR memory-motor task.

\textbf{IVR Memory-Motor Task:} In Figure \ref{fig:looks}, two panels are depicted. On the left side of the figure (Panel I), we observe the external view of a participant wearing the OVR, ready to commence the IVR Memory-Motor Task. Panel II on the right side of the figure showcases four out of the five steps participants undergo when initiating a trial set. These steps are outlined below:


\begin{enumerate}
    \item[\textbf{a.}] Participants stand in front of a virtual table, allowing ample time to acclimate to the virtual environment, as depicted in Figure \ref{fig:looks}. When they feel prepared, the session commences as they calibrate by placing their hands on the virtual table.

    \item[\textbf{b.}] Prior to each trial within every set, a new calibration process begins. Participants place their palms facing up within the shadowed hands, ensuring standardized positioning. Refer to Figure \ref{fig:looks} (b) for the calibration setup.
    
    \item[\textbf{c.}] Once the calibration is complete, a two-dimensional sketch appears in front of them (Figure \ref{fig:looks} (c)), prompting them to memorize the red ball's position. Participants then observe a template on the table, resembling the initial sketch they memorized. Their task is to place the ball swiftly and accurately in the correct location on the template. In the memory-sketch, the relevant position of the ball is denoted by the red circle. During this phase, participants keep their virtual hands open with palms facing up.
    
    \item[\textbf{d.}] As soon as the memory-sketch disappears, a red ball appears in either the left or right hand of the participants. Simultaneously, a vibration could start in the glove. The vibration may or may not match the visual location of the red ball. If the vibrating hand matches the visual location of the ball, the condition is congruent ($V=T$). If the vibrating hand does not match the visual location of the ball, then the trial is incongruent ($V \neq T$). If there is no vibration at all, the condition is purely visual ($V$).
   
    \item[\textbf{e.}] After placing the ball on the template, the ball and template disappear. The whole process from (b) to (e) repeats.
\end{enumerate}

\begin{figure}[!ht]
    \centering
    \includegraphics[width=15cm]{/home/perdices/Dokumente/Github/m-b_thesis/Analysis/figures/design_ilustration.png}
    \put(-420,240){\textbf{I}} % Adjust (-20,340) to position "I" label as desired
    \put(-320,240){\textbf{II}} % Adjust (360,340) to position "II" label as desired
    \captionsetup{justification=justified, margin={2cm,2cm}, font={small}}
    \caption{Illustration of the IVR Memory-Motor Task: Panel I show a participant wearing equipment. Panel II shows step (a) represents the acclimation period during initial setup and first step calibration; (b) showcases the first-person perspective of the second calibration phase; (c) displays the 2D sketch for memorizing ball position; (d) presents the appearance of the ball and the 3D template for ball placement, marking the beginning of each trial.}
    \label{fig:looks}
\end{figure}
 
In a sequence of 108 trials, three conditions—congruent ($V=T$), incongruent ($V \neq T$), and visual-only ($V$)—were presented randomly and rapidly, each occurring 36 times. Each trial commenced upon positioning the ball in a hand, concluding only upon its precise placement on the designated template (refer to Figure \ref{fig:looks}). 

Given that an IVR task inherently involves proprioceptive signals\footnote{Proprioceptive signals arise from our own actions, encompassing signals related to limb and trunk position and movement, sensations of effort, force, and heaviness. Proprioceptive receptors are situated in the skin, muscles, and joints. Information regarding limb position and movement doesn't stem from individual receptors but from clusters of afferents\parencite{Proske2012ThePS}.}, all conditions in the experiment integrate these signals and are thus multimodal. Consequently, the 'visual only' condition doesn't align with the unimodal classification commonly used in psychophysics literature. Nonetheless, for the sake of easier comparison to this literature in this thesis, I will refer to it as unimodal, and the congruent and incongruent conditions as bimodal.


\subsection*{Mesurements}
\subsubsection*{Immersive Virtual Reality (VR):}

Movement data from the data gloves, Leap Motion device, and the HMD was collected. For movement analysis, only the wrist movements tracked by the Leap Motion device were considered, excluding the fingertips' magnetic tracking sensor data. All movements were recorded in a Euclidean coordinate system (X, Y, Z) with the original calibrating point set at (0, 0, 0). This provided a total of nine streaming sources of data (e.g., Headset X, Headset Y, Headset Z, and so on). Notably, rotational data was not included in the analysis.

Additionally, in the game output data, there are flags that signal if a button was pressed, if the ball is placed in the holder, and when the trial started.

\subsubsection*{Questionnaires\footnote{Questionaire validation is outside the scope of this Thesis}:}
Both of the described questionnaires are included in the appendix of this thesis for further reference.

\begin{enumerate}
\item[(i)] \textbf{Virtual Reality Subjective Evaluation Questionnaire:} This self-designed questionnaire comprises 26 items aimed at assessing the sense of reality experienced during the VR session. It explores factors like engagement level, hand movement, task difficulty, and other controlling aspects. Participants responded using a Likert scale rating them on a scale from 1 (Does Not Apply) to 7 (Totally Applies). The questions were organized in groups and inverted to confirm participants' responses. Both questionnaires can be found in the Appendix section.

\item[(ii)] \textbf{PRE/POST-Cybersickness Questionnaire:} This study employs a shortened version of the simulator sickness questionnaire (SSQ) \parencite*{avpsy}. It utilizes a Likert scale ranging from one to four, featuring labels such as "not present," "somewhat," "clearly," and "very strongly." The questionnaire consists of 16 items, gauging symptoms like "fatigue" and "general discomfort," among others.
\end{enumerate}

\subsection*{Data Analysis}

\subsubsection*{Questionnaire}
The analysis of the questionnaire responses aimed to explore the impact of haptic gloves on reported immersion and related perceptions. Initially, the raw questionnaire data collected from 20 respondents, consisting of 27 questions rated on a scale from 1 to 7. Missing values were checked and handled appropriately, thus leaving us with 19. Statistical analysis included the calculation of descriptive statistics such as median ($\text{Mdn}$), mean ($\mu$), and standard deviation ($\sigma$) for each question. These statistics were instrumental in understanding the central tendencies and variability in respondents perceptions. A full view of all answers can be found in the Supplements section. 

\subsubsection*{Response Time}

All response times from the ball's entry into the scene until its disappearance were measured. Trials where the error button was pressed were excluded from the analysis. Prior to analysis, outliers were corrected by eliminating data points deviating more than 3 times the median absolute deviation (MAD), which is equivalent to 3 standard deviations assuming a normal distribution \parencite{Innes2019ACA}. Responses were not eliminated for being too fast; however, 13\% of trials were excluded due to excessive slowness. The final sample comprised 1826 response times (approximately 24 per condition per participant). Subsequent to the removal of outliers, the response times for each condition were transformed into rates (1/RT).

The transformation method entails the inversion of the RT and aligns with prior studies \parencite{Innes2019ACA}. However, this transformation method is not exempt from criticism \parencite{Lo2015-fv}. This study prioritizes normality in error distribution over other factors such as property scale or interacting effects. This prioritization allowed for the direct application of repeated measures ANOVA within subjects. Yet, when the ANOVA results were ambiguous, a General Linear Mixed-Effect Model (GLMM) was additionally applied, as recommended \parencite{Lo2015-fv}. By using GLMM, instead of imposing normality and eliminating error deviation, we allow the use of distributions that match the properties of the measured RT \parencite{Lo2015-fv}. I utilized the \textit{statsmodels} statistical package in Python, specifically the \textit{mixedlm} function, similar to other studies \parencite{RSE_FBI}. Although this analysis is not present in the reference study, the utilization of GLMM aims to provide clarity regarding the significance of the conditions and the study's power.

\subsubsection*{Redundancy Signal Effect and Race Model Inequality}

As previously mentioned, the Multisensory Integration reference in this thesis utilized the redundant signal effect and race model inequality to explain the heart cycle effect in multisensory integration. In the cited paper, Race Model approaches suggest that elements from two unimodal stimuli undergo processing in distinct sensory channels, with the fastest one prompting the response (essentially, it "wins the race"). The RMI serves to dismiss the idea that quicker response times (RTs) could be explained by separate processing (i.e., Race Model). It posits that the combined RTs distribution for redundant stimuli never surpasses the total of the RTs distribution for the individual unimodal stimuli. Rejecting this notion indicates interactions across multiple senses.

However, reaching this conclusion in this thesis cannot follow the same methodology as our reference study\footnote{The procedure in the reference study involved clustering raw RTs into 21 progressively increasing time bins. Initially, a specific RT range was determined for each participant by calculating the difference between their slowest and fastest RTs. Subsequently, 5\% of this range was incrementally added to each time bin to create the bins. The cumulative distribution frequency (CDF) was established by summing the total probabilities across these quantized bins, resulting in 11-time bins (0\%, 0\% + 10\%, 0\% + 10\% + 20\%, etc.) for each of the three multisensory pairs. Detailed steps in \textcite{Mahoney2019-yq}.} due to unique characteristics. For example, a constant proprioceptive signal is inherent in the IVR design across all conditions. Additionally, having only one individual unimodal stimulus prevents constructing the complete distribution of reaction times for individual unimodal stimuli since not all modalities are individually measured. Nevertheless, comparisons between the congruent and incongruent conditions with the single modality condition ($V$) can be made. Furthermore, constructing cumulative distribution functions allows testing the statistical significance of these differences.

Therefore, let's outline the formal definition of our specific case of the race inequality model in equations (1) and (2):
\[
F_y(t) \leq F_x(t), \quad t > 0, \quad (1)
\]
\[
F_z(t) \leq F_x(t), \quad t > 0, \quad (2)
\]

Here, $F_x$ represents the cumulative density functions (CDFs) of reaction times (RT) in the individual stimulus conditions visual-only ($V$), respectively, while $F_y$ and $F_z$ denote the CDF of RT in the redundant-stimulus conditions congruent ($V=T$) and incongruent ($V \neq T$). According to race models, there's a possibility for $F_z(t)$ or $F_y(t)$ to closely approach $F_x(t)$ for small values of $t$, particularly in scenarios with strongly negative correlations in detection times \parencite*{Ulrich2007}. However, even under these circumstances, the inequality must still hold true as per the race models.

The process involved generating empirical cumulative density functions (CDFs) for three conditions—Bimodal pairs and Single Signal—and followed the steps outlined in literature \parencite*{Ulrich2007}. The first steps were followed for every participant and every stimulus condition. Specifically, let $G_x$ be the individual CDF estimate of the visual-only condition, and $F_y$ and $F_z$ denote the redundant CDF for the incongruent and congruent conditions.

Consider a scenario where a set $\{x_1, x_2, \ldots , x_n\}$ of $n$ reaction times (RTs) has been recorded within condition $V$ for a specific participant. Arranging this sample in ascending order, from the smallest value to the largest—$x_1 \leq x_2 \leq \ldots \leq x_n$—one creates a step function. The second step involves using a step function to generate a cumulative frequency polygon. The final step is the estimation of percentiles and aggregation across participants. For a comprehensive breakdown and reference code, consult \cite{Ulrich2007}. Additionally, code for this thesis is shared on GitHub.

To mimic the results from \Cite{SALTAFOSSI2023108642}, I conducted a series of t-tests using individual participant data for the $F_x$, $F_y$ and $F_z$ values at each percentile level. Rather than examining areas under the curve, I focused on the raw values of $F_x$, $F_y$ and $F_z$. Furthermore, instead of emphasizing time bins, I opted to discuss percentile levels, given the differing time ranges compared to traditional RMI literature are longer because of answering times in IVR task.

\section*{Results}
\subsection*{Questionnaires}
 
All participants were right-handed and exhibited a significant increase in reported sickness. A comparison between Pre and Post VR-Cybersickness Questionnaires indicated a rise in the average cybersickness among all experiment participants. Overall results leaned towards symptoms being "not present". We performed a paired-samples t-test to assess the cybersickness levels before (Pre) and after (Post) the Virtual Reality Experience. There was a significant difference in the scores between the Pre (M=1.10, SD=0.12) and Post (M=1.18, SD=0.19) conditions; $t(21)=-2.65$, $p = 0.015$. On average, the symptoms moved from "not present" to "somewhat present". 

\subsubsection*{Virtual Reality Subjective Evaluation Questionnaire}
Nineteen respondents answered 27 questions, rating them on a scale from 1 (Does Not Apply) to 7 (Totally Applies). The key facts from the questionnaire are as follows:
    
In question number 24, the reported score for the question of a perceived increase in immersion due to the haptic gloves was high ($\text{Mdn} = 6$, $\mu = 6$, $\sigma = 0.76$). Furthermore, the task was considered enjoyable at least some of the time ($\text{Mdn} = 6$, $\mu = 5.4$, $\sigma = 1.04$).
        
Question 26 revealed that haptic feedback was perceived as either not significantly improving performance or having a neutral effect ($\text{Mdn} = 3$, $\mu = 3.6$, $\sigma = 1.49$). Similarly, in question 12, the perception of haptic feedback improving response time was generally rated as neutral to not applicalbe ($\text{Mdn} = 3$, $\mu = 3.7$, $\sigma = 1.74$). In question 7, when asked about the impact on results, haptic feedback was perceived as not applicable as well ($\text{Mdn} = 6$, $\mu = 6$, $\sigma = 0.76$).
    
Notably, the assertion that it was very challenging to remember the position of the red ball ($\text{Mdn} = 2$, $\mu = 2.9$, $\sigma = 1.45$) was generally disagreed upon. Conversely, in question 8, which asked the inverse question about the ease of remembering the location of the red ball ($\text{Mdn} = 5$, $\mu = 5.1$, $\sigma = 1.37$) allign with its counterfactual and it is report as highly easy. 
    
The highest variance was observed in question 13 ($\text{Mdn} = 5$, $\mu = 4.2$, $\sigma = 1.79$), indicating that haptic feedback made it easier to place the ball. Similarly, question 18, which inquired about the ease of counting heartbeats at the beginning of the experiment, also showed significant variance ($\text{Mdn} = 4$, $\mu = 4$, $\sigma = 1.79$). 
    
Overall, participants reported increased immersion and enjoyment as a result of the added gloves. However, there was no perceived enhancement in response attributed to the presence of the gloves and the IVR ball placing task was considered easy. Moreover, the notably high variance observed in the last two questions may suggest potential confusion among participants regarding these specific queries or significant individual differences in experiences. For a more detailed breakdown, please refer to the supplementary section.
    
\subsection*{Influence of Touch Stimuli on Response Time}
\subsubsection*{General Performance}

Initially, I assessed the mistake rates in ball placement across different conditions to ensure their negligible impact on the experiment. The mistake rates were as follows: in the visual-only condition ($V$), it was $6.35\%$ ($\pm 0.99\%$, SEM); in the visual incongruent touch condition ($V \neq T$), it was $5.79\%$). Additionally, a one-way ANOVA (feedback type) indicated no significant effects ($ F \leq 0.08$, $p \geq 0.91$). This task is considerably more complex than a simple yes-no detection task. Therefore, to some extent, we anticipate a higher mistake rate. Nevertheless, these rates remain notably low and were not subjected to further analysis.

To investigate whether the experimental manipulations succesfully manipulated RT, I conducted a one-way repeated-measures ANOVA. The test revealed a significant main effect for the stimulus ($F(2,38) = 3.4$, $p \leq 0.043$, $\eta p^2 = 0.15$). The median response time for the 'Congruent' condition ($V=T$) was the fastest ($3236$ ms $\pm 456$ ms), followed by the 'Incongruent' ($V \neq T$) condition ($3268$ ms $\pm 470$), while the slowest was observed in the absence of haptic stimuli 'None' ($V$) ($3284$ ms $\pm 463$). Thus, the experimental conditions significantly influenced response times, as illustrated in Figure \ref{fig:error}. However, post hoc Tukey HSD tests did not reveal any specific pairwise differences. While an overall difference among conditions was observed, specific pairwise differences were not identified.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=15cm]{/home/perdices/Dokumente/Github/m-b_thesis/Analysis/figures/bar_erros_bars_stimulus_constructions.png}
    \captionsetup{justification=justified, margin={2cm,2cm}, font={small}}
    \caption{One-way repeated-measures ANOVA using $RT^{-1}$. The test revealed a significant main effect for the conditions ($F(2,38) = 3.4$, $p \leq 0.043$, $\eta p^2 = 0.15$)}
    \label{fig:error}
\end{figure}

Given the absence of identified specific pairwise differences in the post hoc analysis, I conducted a more comprehensive investigation using a Generalized Linear Mixed Model (GLMM). While not employed in the referenced paper, this method offers numerous advantages in multilevel research designs. It addresses the issue of linear relationship between the standard deviation of RT nd mean R, characterized by an increasing spread in residuals for longer predicted RT  \parencite{Lo2015-fv}.

The mixed linear model analysis aimed to assess the impact of feedback types (($V=T$), ($V \neq T$), ($V$)) on response times. The model included feedback type as a fixed effect and participant as a random effect, with the 'Congruent' feedback type serving as the reference category.

The model coefficient for the 'None' ($V$) feedback type ($\beta = 45.726, SE = 22.594, p = 0.043$) reached statistical significance at the conventional level ($\alpha =0.05 $) when compared to the 'Congruent' ($V=T$) feedback type. This suggests a significant difference in response times between the 'None' and 'Congruent' feedback types. The coefficient for the 'Incongruent' feedback type ($\beta = 32.975, SE = 22.686, p = 0.146$) did not reach conventional levels of significance.

Thus, the 'Congruent' condition demonstrated significantly faster performance compared to the visual-only condition. This outcome aligns with the expected results according to the RSE. However, the findings present a mixed perspective. Despite this significant contrast, the more stringent post hoc Tukey HSD tests revealed no notable differences between pairwise conditions. Additionally, the GLMM indicated significance solely between the 'Congruent' and visual-only ($V=T$ - $V$) conditions and not between the 'Congruent' and 'Incongruent' conditions ($V=T$ - $V \neq T$). To understand if this mixed results are due to the irrelevancy of the 'Incongruent' condition ($V \neq T$) or the result of changed behavior over time, CDF analysis will help complement the model.

\subsubsection*{Race Model Inequeality}

Here I use the CDF from the RMI model to assess the significance of their differences throughout different $t$ and establish comparisons among the three experimental conditions. We observed that the overall performance partially adhered to the RSE, notably between the 'Congruent' and visual-only ($V=T$ ; $V$) conditions, but no significant differences emerged between the 'Congruent' and 'Incongruent' conditions ($V=T$ ; $V \neq T$). 

When comparing differences between $F_x$ and $F_y$ ($V$ ; $V \neq T$), no significant p-values were found for any percentile. The results between $F_x$ and $F_z$ ($V$; $V=T$) are presented in Table \ref{tab:response-time-range}. This table illustrates the results for all time frames and percentiles. Notably, significant differences emerged between $F_x$ and $F_y$ from percentile 16 onwards. Interestingly, for this percentile (as depicted in Figure \ref{fig:CDF}), the single modality visual ($V$) appears to be faster than the bimodal incongruent condition ($V \neq T$), suggesting a potential violation of the RSE. Conversely, from percentile 40 onwards both redundant signals are consistenly faster than the unimodal signal, results that align with our expectations from the RSE. It's important to note that when considering the distribution of all response times, the highest density is observed between 3100 and 3200 ms (33\% of all RT).
 
\begin{table}[!ht]
    \centering
    \begin{tabular}{ccccc}
    \hline
    \textbf{$F_x$ Time Range (ms)} & \textbf{$F_x$ Min Max Diff (ms)} & \textbf{Percentile Estimation} & \textbf{T-value} & \textbf{p-value} \\ \hline
    (3070, 3621) & 551 & 10  & 1.19 & 0.12 \\
    (3078, 3626) & 548 & 13 & 1.31 & 0.1  \\
    (3084, 3648) & 564 & 16 & 1.88 & 0.04* \\
    (3086, 3687) & 600 & 19 & 2.04 & 0.03* \\
    (3087, 3708) & 621 & 20  & 2.01 & 0.03* \\
    (3092, 3748) & 656 & 23 & 1.97 & 0.03* \\
    (3094, 3760) & 665 & 26 & 2.06 & 0.03* \\
    (3098, 3766) & 668 & 29 & 2.03 & 0.03* \\
    (3099, 3768) & 668 & 30  & 2.02 & 0.03* \\
    (3104, 3814) & 709 & 33 & 2.11 & 0.02* \\
    (3106, 3838) & 732 & 36 & 2.08 & 0.03* \\
    (3111, 3846) & 735 & 39 & 1.83 & 0.04* \\
    (3114, 3848) & 734 & 40  & 1.79 & 0.04* \\
    (3119, 3861) & 741 & 43 & 1.74 & 0.05* \\
    (3121, 3907) & 786 & 46 & 1.55 & 0.07  \\
    (3123, 3969) & 846 & 49 & 1.36 & 0.09  \\
    (3124, 3978) & 855 & 50  & 1.33 & 0.1   \\
    (3130, 4171) & 1041 & 60  & 1.25 & 0.11  \\
    (3141, 4352) & 1211 & 70  & 1.21 & 0.12  \\
    (3153, 4645) & 1492 & 80  & 1.47 & 0.08  \\
    (3176, 4948) & 1772 & 90 & 0.53 & 0.3   \\ \hline
    \end{tabular}
    \captionsetup{justification=justified, margin={2cm,2cm}, font={small}}
    \caption{T-test results between $F_x$ \& and $F_z$ conditions. Response Time Range (ms), Difference RT (ms), Percentile Estimation, T-value, and p-value for each Percentile using the results of t-tests. * indicates significant p-values.}
    \label{tab:response-time-range}
\end{table}


\begin{figure}[!ht]
    \centering
    \includegraphics[width=\textwidth]{/home/perdices/Dokumente/Github/m-b_thesis/Analysis/figures/CDF.png}
    \captionsetup{justification=justified, margin={2cm,2cm}, font={small}}
    \caption{ (a.) Displays the 10 estimated percentile points for each of the three functions of interest: $F_x$, $F_y$, $F_z$, considering all participants. (b.) Is a zoom in the first 100 ms. Acording to the RSE, the visual $V$ type should be under $F_y$, $F_z$ at all moments. Our data shows that is not the case for the RT in the first 200 ms.}
    \label{fig:CDF}
\end{figure}


\section*{Discussion}

This thesis test the feasibility of using IVR to investigate how the cardiac cycle modulates cognition. By doing so to start bridging the gap between cognitive and psychophysical research. To accomplish this goal, an IVR memory task is employed where participants must remember a location and immediately place a red ball over this location in a 3D template. The condition is designed so that a passive vibro-tactile stimulus is activated along with the ball being placed, matching either the visual location of the ball or in the opposite hand. The study employs a within-subject experimental design with three categories: congruent visual-tactile stimuli ($V=T$), incongruent visual-tactile stimuli ($V \neq T$), and visual-only stimuli ($V$). The participants answered cibersickness questionnaire, Inmersion measured parameters are Reaction Time (RT) and Accuracy.

To test if the IVR set up can mimic existing literature, the steps outlined in my reference studies \parencite{Innes2019ACA, SALTAFOSSI2023108642, Ulrich2007} are followed. It is important to note that throughout all conditions propioceptive signal is relevant and only one single modality stimulus ($V$) is used, therefore limiting the possibilities of RMI comparisons. This study builds an aporximate approach.

Over a third of all trials were answered within 3100 ms and 3200 ms, making it the mos frequent time bin. The initial step of anaylsis involves validating stimulus construction by analyzing and modeling reaction times for uni-modal and bi-modal stimuli. The results present a mixed picture, indicating an overall significant difference between the conditions. However, while attempting to identify pairwise differences using a Tukey HSD test, no significant distinctions are found. Nevertheless, a GLMM indicates a notable difference between the visual-only ($V$) and visual-touch congruent ($V=T$) conditions. There are no significant variances observed between the incongruent ($V \neq T$) and visual-only ($V$) conditions. These findings confirm the well-established Redundant Signals Effect (RSE) in virtual reality during a ball positioning task and prompt inquiries about the incongruent condition. Specifically, the incongruent condition mostly aligns temporally between the congruent and incongruent conditions throughout the entire time period $t$ (as illustrated in Figure \ref{fig:error}).

The question arises whether the incongruent condition demonstrates more erratic behavior and overlaps significantly with both significant conditions, or if it exhibits significant changes throughout different time periods. This could be addressed through a study with higher statistical power.

The RMI analysis indicates a significant disparity in the cumulative distribution functions (CDF) between conditions when conducting a between-participants t-test for $F_x$ and $F_z$. This discrepancy occurs specifically within the timeframe of 3100 ms to 3200 ms, rather than before or after. Moreover, no significant differences were observed for $F_x$ and $F_y$ during this 100 ms period or thereafter. 

Descriptively, the relationship between the visual-only ($V$) and congruent condition ($V=T$) remains consistent across the entire range of reaction times (RT), aligning with the Redundant Signals Effect (RSE). However, this pattern doesn’t hold to the RT relation between the incongruent condition ($V \neq T$) and the visual-only condition ($V$), where initially, within the first 100 ms of the trial, the visual-only condition displays faster responses than the incongruent condition ($V \neq T$), potentially breaching the expected inequality. Subsequently, the incongruent condition is faster than the unimodal visual-only condition, as anticipated. This again raises the question aover a possible violation of the RMI model. Particularly as a bimodal condition ($V \neq T$) demonstrates slower responses compared to a unimodal condition ($V$).

Another study investigating embodiment illusion yielded similar results concerning the irrelevance of stimuli for reaction times (RT). Their hypothesis suggests that the absence of a difference in the Redundant Signals Effect (RSE) between congruent and incongruent conditions could be due to the mere simultaneous occurrence of visual and vibrotactile stimuli. This simultaneous presence might suffice for multisensory integration, regardless of whether these multisensory stimuli are functionally linked at a higher level or not (e.g., touch in the hand holding the ball)\parencite{RSE_FBI}.

This explanation seems to apply to the responses after the 40th percentile and the overall results, but it doesn't account for the observed first 100 ms, indicating a potential violation of the RMI.

Another explanation might be related to the context invariance assumption, which posits that the processing of one signal is unaffected by another. As previously mentioned, the discrepancy observed in the incongruent case might be so minimal that the statistical power of the present study might not be sufficient to detect it significantly.

Considering the study's statistical power, one conclusion drawn is that, for ecological validity reasons, each trial in our IVR study spans a longer time frame compared to traditional psychophysics experiments (with a mean duration of 3400 ms versus the typical 200 ms). This extended duration contributes to increased variance and skewness in reaction times (RT). Additionally, according to the literature, the influence of the cardiac cycle on stimuli ranges from 10 to 40 ms, posing a challenge when investigating its effects in IVR environments.

Therefore, it becomes necessary to triple the statistical power of future research, involving, for instance, 60 participants, especially if an additional condition related to cardiac cycles is included in the analysis. Additionally, new markers should be incorporated into the task, and a new analysis with shorter projected RT should be included—from the moment the ball is inserted to the moment it is initiated.  


\newpage
\begin{figure}[H]
        \centering
        \includegraphics[angle=90, width=\textwidth, height=20cm, keepaspectratio]{/home/perdices/Dokumente/Github/m-b_thesis/Analysis/figures/questionaire_fig.png}
        \captionsetup{justification=justified, margin={2cm,2cm}, font={small}}
        \caption{Results: Virtual Reality Subjective Evaluation Questionnaire}
        \label{fig:quest}
\end{figure}
\pagebreak


%-------- CREATING BIBLIOGRAPHY

\paragraph{\textbf{References}}
\printbibliography[heading=none]

%-------- CREATING Apendix

\pagebreak
\vspace*{\fill}
\section*{\centering Additional Material}
\vspace*{\fill}



\end{document}

